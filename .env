# --------------------------------------- âš™ï¸ WORDCAB TRANSCRIBE CONFIGURATION ---------------------------------------- #
#
# Do not remove this file or any of the variables below.
# You can only modify the values of the variables to customize the configuration of the API.
#
# ---------------------------------------------- GENERAL CONFIGURATION ----------------------------------------------- #
#
# The name of the project, used for API documentation.
PROJECT_NAME="Wordcab Transcribe"
# The version of the project, used for API documentation.
VERSION="0.3.1"
# The description of the project, used for API documentation.
DESCRIPTION="ðŸ’¬ ASR FastAPI server using faster-whisper and NVIDIA NeMo."
# This API prefix is used for all endpoints in the API outside of the status and cortex endpoints.
API_PREFIX="/api/v1"
# Debug mode for FastAPI. It allows for hot reloading when code changes in development.
DEBUG=True
#
# ----------------------------------------------- BATCH CONFIGURATION ------------------------------------------------ #
#
# The batch_size parameter is used to control the number of audio files that are processed in parallel.
# If your server GPU has a lot of memory, you can increase this value to improve performance.
# For simplicity, we recommend leaving this value at 1, unless you are sure that your GPU has enough memory (> 40GB)
BATCH_SIZE=1
# The max_wait parameter is used to control the maximum amount of time (in seconds) that the server will wait for
# processing the tasks in the queue, if not empty. It's useful only when the batch_size is greater than 1.
MAX_WAIT=0.1
#
# ----------------------------------------------- MODELS CONFIGURATION ----------------------------------------------- #
#
# ----------------------------------------------------- WHISPER ------------------------------------------------------ #
#
# The whisper_model parameter is used to control the model used for ASR.
#
# Cloud models:
# The available models are: tiny, tiny.en, base, base.en, small, small.en, medium, medium.en, large-v1, or large-v2
# You can try different model size, but you should see a trade-off between performance and speed.
#
# Local models:
# You can also link a local folder path to use a custom model. If you do so, you should also mount the folder in the
# docker run command as a volume.
# e.g. WHISPER_MODEL="/app/models/custom"
# docker cmd: -v /path/to/custom/model:/app/models/custom
WHISPER_MODEL="large-v2"
# The compute_type parameter is used to control the precision of the model. You can choose between:
# "int8", "int8_float16", "int16", "float_16". The default value is "int8_float16", which is the fastest option with
# minimal loss in accuracy using the `large-v2` model.
COMPUTE_TYPE="float16"
# The extra_languages parameter is used to control the languages that need an extra model to be loaded.
# You can specify multiple languages separated by a comma. The available languages are: `he` (Hebrew).
EXTRA_LANGUAGES=""
#
# --------------------------------------------------- NVIDIA NEMO ---------------------------------------------------- #
#
# The nemo_domain_type define the configuration file used by the model for diarization. The available options are:
# `general`, `meeting` and `telephonic`. The default value is `telephonic`. If you choose another type, you will need
# to provide a custom model
NEMO_DOMAIN_TYPE="telephonic"
# The nemo_storage_path parameter is used to control the path where the NeuralDiarizer from the NeMo toolkit will
# store the diarization models.
NEMO_STORAGE_PATH="nemo_storage"
# The nemo_output_path parameter is used to control the path where the NeuralDiarizer from the NeMo toolkit will
# store the diarization outputs.
NEMO_OUTPUT_PATH="nemo_outputs"
#
# ---------------------------------------------- ASR TYPE CONFIGURATION ---------------------------------------------- #
#
# The asr_type parameter is used to control the type of ASR used. The available options are: `async` or `live`.
# * `async` is the default option. It will process the audio files in batches, and return the results when all the
# files are processed.
# * `live` is the option to use when you want to process a live audio stream. It will process the audio in chunks,
# and return the results as soon as they are available. Live option is still a feature in development.
# Use `live` only if you need live results, otherwise, use `async`.
ASR_TYPE="async"
#
# --------------------------------------------- ENDPOINTS CONFIGURATION ---------------------------------------------- #
#
# Include the `audio` endpoint in the API. This endpoint is used to process uploaded local audio files.
AUDIO_FILE_ENDPOINT=True
# Include the `audio-url` endpoint in the API. This endpoint is used to process audio files from a URL.
AUDIO_URL_ENDPOINT=True
# Include the cortex endpoint in the API. This endpoint is used to process audio files from the Cortex API.
# Use this only if you deploy the API using Cortex and Kubernetes.
CORTEX_ENDPOINT=True
# Include the `youtube` endpoint in the API. This endpoint is used to process audio files from YouTube URLs.
YOUTUBE_ENDPOINT=True
# Include the `live` endpoint in the API. This endpoint is used to process live audio streams.
LIVE_ENDPOINT=False
#
# ---------------------------------------- API AUTHENTICATION CONFIGURATION ------------------------------------------ #
# The API authentication is used to control the access to the API endpoints.
# It's activated only when the debug mode is set to False.
#
# The username and password are the credentials used to authenticate with the API.
USERNAME="admin"
PASSWORD="admin"
# This openssl_key parameter is used to control the key used to encrypt the access tokens.
# You should absolutely change this value before deploying the API in production.
OPENSSL_KEY="0123456789abcdefghijklmnopqrstuvwyz"  # <--- CHANGE ABSOLUTELY THIS VALUE
# This openssl_algorithm parameter is used to control the algorithm used to encrypt the access tokens.
# You should in most case not change this value.
OPENSSL_ALGORITHM="HS256"
# The access_token_expire_minutes parameter is used to control the expiration time of the access tokens.
# You can modify it, it's not a critical parameter. Note that this parameter is in minutes.
ACCESS_TOKEN_EXPIRE_MINUTES=30
#
# ---------------------------------------------- CORTEX CONFIGURATION ------------------------------------------------ #
#
# The cortex_api_key parameter is used to control the API key used to authenticate the requests to the cortex endpoint.
WORDCAB_TRANSCRIBE_API_KEY=
#
# ----------------------------------------------- SVIX CONFIGURATION ------------------------------------------------- #
#
# The svix_api_key parameter is used in the cortex implementation to enable webhooks.
SVIX_API_KEY=
# The svix_app_id parameter is used in the cortex implementation to enable webhooks.
SVIX_APP_ID=
#
# -------------------------------------------------------------------------------------------------------------------- #
